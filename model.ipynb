{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Machine learning metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline\n",
    "def process_data(df):\n",
    "    \"\"\"\n",
    "    Prepare data that can be readily consumed by ML/DL algorithms.\n",
    "    - remove elevation outliers for Spruce/Fir and Lodgepole Pine\n",
    "    - separate features from class variables\n",
    "    - split into training and testing dataset\n",
    "    - scale numerical data\n",
    "    \n",
    "    param: a dataframe of input data\n",
    "    output: X_train_normalized, X_test_normalized, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Remove elevation outliers for Spruce/Fir\n",
    "    df_drop_outliers = df.drop(df[(df['class'] == 1) & (df['Elevation'] < 2730) | (df['Elevation'] > 3538)].index)\n",
    "    # Remove elevation outliers for Lodgepole Pine\n",
    "    df_drop_outliers = df.drop(df[(df['class'] == 2) & (df['Elevation'] < 2422) | (df['Elevation'] > 3414.0)].index)\n",
    "\n",
    "    # Split data into features and labels\n",
    "    df_features = df_drop_outliers.iloc[:, :-1]\n",
    "    # We subract 1 from every class value to include 0 as a label for the softmax\n",
    "    df_labels = df_drop_outliers['class'] \n",
    "\n",
    "    # Split into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, df_labels, test_size=0.2, stratify=df_labels)\n",
    "\n",
    "    # Normalise data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_normalized, X_test_normalized, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML pipeline\n",
    "def build_model(features):\n",
    "    \"\"\"\n",
    "    Build the model architecture (and compile it).\n",
    "    input: number of features\n",
    "    output: Keras model object.\n",
    "    \"\"\"    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(features.shape[1])))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Summary report of Keras classifier:\")\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read csv\n",
    "    filename = 'cover_data.csv'\n",
    "    print(f\"Reading {filename}\")\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Process data\n",
    "    X_train, X_test, y_train, y_test = process_data(df)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    # Build Deep Learning Model\n",
    "    model = build_model(X_train)\n",
    "\n",
    "    # Set params\n",
    "    num_epochs = 100\n",
    "    batch_size = 1024\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=5)\n",
    "    \n",
    "    # Build model\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=num_epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        callbacks=[es], \n",
    "                        validation_split=0.1, \n",
    "                        verbose=1)\n",
    "\n",
    "    # Evaluate model\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {score[0]}\")\n",
    "    print(f\"Test accuracy: {score[1]}\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions to discrete values\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    class_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
    "                   'Ponderosa Pine', 'Cottonwood/Willow',\n",
    "                   'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cover_data.csv\n",
      "(457120, 54)\n",
      "(457120,)\n",
      "(114280, 54)\n",
      "(114280,)\n",
      "Summary report of Keras classifier:\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 128)               7040      \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,640\n",
      "Trainable params: 17,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "402/402 [==============================] - 3s 6ms/step - loss: 0.8398 - accuracy: 0.6592 - val_loss: 0.6130 - val_accuracy: 0.7387\n",
      "Epoch 2/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.6437 - accuracy: 0.7274 - val_loss: 0.5651 - val_accuracy: 0.7563\n",
      "Epoch 3/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.6028 - accuracy: 0.7427 - val_loss: 0.5339 - val_accuracy: 0.7670\n",
      "Epoch 4/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5768 - accuracy: 0.7524 - val_loss: 0.5111 - val_accuracy: 0.7785\n",
      "Epoch 5/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5563 - accuracy: 0.7604 - val_loss: 0.4941 - val_accuracy: 0.7854\n",
      "Epoch 6/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5412 - accuracy: 0.7671 - val_loss: 0.4767 - val_accuracy: 0.7964\n",
      "Epoch 7/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5285 - accuracy: 0.7736 - val_loss: 0.4621 - val_accuracy: 0.8015\n",
      "Epoch 8/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5177 - accuracy: 0.7792 - val_loss: 0.4540 - val_accuracy: 0.8069\n",
      "Epoch 9/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5079 - accuracy: 0.7832 - val_loss: 0.4432 - val_accuracy: 0.8129\n",
      "Epoch 10/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.5006 - accuracy: 0.7865 - val_loss: 0.4342 - val_accuracy: 0.8167\n",
      "Epoch 11/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4925 - accuracy: 0.7901 - val_loss: 0.4250 - val_accuracy: 0.8216\n",
      "Epoch 12/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4869 - accuracy: 0.7930 - val_loss: 0.4206 - val_accuracy: 0.8231\n",
      "Epoch 13/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4811 - accuracy: 0.7959 - val_loss: 0.4134 - val_accuracy: 0.8283\n",
      "Epoch 14/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4771 - accuracy: 0.7971 - val_loss: 0.4061 - val_accuracy: 0.8297\n",
      "Epoch 15/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4721 - accuracy: 0.7997 - val_loss: 0.4024 - val_accuracy: 0.8320\n",
      "Epoch 16/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4679 - accuracy: 0.8018 - val_loss: 0.3994 - val_accuracy: 0.8338\n",
      "Epoch 17/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4637 - accuracy: 0.8029 - val_loss: 0.3933 - val_accuracy: 0.8367\n",
      "Epoch 18/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4605 - accuracy: 0.8049 - val_loss: 0.3893 - val_accuracy: 0.8378\n",
      "Epoch 19/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4597 - accuracy: 0.8056 - val_loss: 0.3872 - val_accuracy: 0.8386\n",
      "Epoch 20/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4554 - accuracy: 0.8069 - val_loss: 0.3841 - val_accuracy: 0.8395\n",
      "Epoch 21/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4536 - accuracy: 0.8082 - val_loss: 0.3815 - val_accuracy: 0.8410\n",
      "Epoch 22/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4525 - accuracy: 0.8088 - val_loss: 0.3777 - val_accuracy: 0.8427\n",
      "Epoch 23/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4478 - accuracy: 0.8107 - val_loss: 0.3754 - val_accuracy: 0.8413\n",
      "Epoch 24/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4470 - accuracy: 0.8106 - val_loss: 0.3751 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4448 - accuracy: 0.8122 - val_loss: 0.3682 - val_accuracy: 0.8481\n",
      "Epoch 26/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4436 - accuracy: 0.8122 - val_loss: 0.3705 - val_accuracy: 0.8475\n",
      "Epoch 27/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4418 - accuracy: 0.8136 - val_loss: 0.3665 - val_accuracy: 0.8484\n",
      "Epoch 28/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4407 - accuracy: 0.8145 - val_loss: 0.3650 - val_accuracy: 0.8504\n",
      "Epoch 29/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4384 - accuracy: 0.8155 - val_loss: 0.3655 - val_accuracy: 0.8509\n",
      "Epoch 30/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4379 - accuracy: 0.8160 - val_loss: 0.3608 - val_accuracy: 0.8516\n",
      "Epoch 31/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4353 - accuracy: 0.8165 - val_loss: 0.3584 - val_accuracy: 0.8519\n",
      "Epoch 32/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4338 - accuracy: 0.8171 - val_loss: 0.3594 - val_accuracy: 0.8514\n",
      "Epoch 33/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4332 - accuracy: 0.8172 - val_loss: 0.3580 - val_accuracy: 0.8528\n",
      "Epoch 34/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4332 - accuracy: 0.8175 - val_loss: 0.3561 - val_accuracy: 0.8533\n",
      "Epoch 35/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4310 - accuracy: 0.8183 - val_loss: 0.3543 - val_accuracy: 0.8536\n",
      "Epoch 36/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4303 - accuracy: 0.8191 - val_loss: 0.3531 - val_accuracy: 0.8530\n",
      "Epoch 37/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4283 - accuracy: 0.8203 - val_loss: 0.3531 - val_accuracy: 0.8548\n",
      "Epoch 38/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4276 - accuracy: 0.8201 - val_loss: 0.3496 - val_accuracy: 0.8557\n",
      "Epoch 39/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4265 - accuracy: 0.8198 - val_loss: 0.3487 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4253 - accuracy: 0.8204 - val_loss: 0.3489 - val_accuracy: 0.8575\n",
      "Epoch 41/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4242 - accuracy: 0.8211 - val_loss: 0.3466 - val_accuracy: 0.8576\n",
      "Epoch 42/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4242 - accuracy: 0.8212 - val_loss: 0.3462 - val_accuracy: 0.8558\n",
      "Epoch 43/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4231 - accuracy: 0.8222 - val_loss: 0.3461 - val_accuracy: 0.8587\n",
      "Epoch 44/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4224 - accuracy: 0.8227 - val_loss: 0.3473 - val_accuracy: 0.8570\n",
      "Epoch 45/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4213 - accuracy: 0.8236 - val_loss: 0.3422 - val_accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4212 - accuracy: 0.8226 - val_loss: 0.3415 - val_accuracy: 0.8602\n",
      "Epoch 47/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4197 - accuracy: 0.8236 - val_loss: 0.3427 - val_accuracy: 0.8603\n",
      "Epoch 48/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4205 - accuracy: 0.8230 - val_loss: 0.3400 - val_accuracy: 0.8609\n",
      "Epoch 49/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4177 - accuracy: 0.8243 - val_loss: 0.3388 - val_accuracy: 0.8604\n",
      "Epoch 50/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4182 - accuracy: 0.8243 - val_loss: 0.3372 - val_accuracy: 0.8617\n",
      "Epoch 51/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4175 - accuracy: 0.8243 - val_loss: 0.3375 - val_accuracy: 0.8626\n",
      "Epoch 52/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4163 - accuracy: 0.8249 - val_loss: 0.3357 - val_accuracy: 0.8620\n",
      "Epoch 53/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4175 - accuracy: 0.8244 - val_loss: 0.3375 - val_accuracy: 0.8631\n",
      "Epoch 54/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4168 - accuracy: 0.8254 - val_loss: 0.3375 - val_accuracy: 0.8626\n",
      "Epoch 55/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4150 - accuracy: 0.8256 - val_loss: 0.3365 - val_accuracy: 0.8636\n",
      "Epoch 56/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4151 - accuracy: 0.8264 - val_loss: 0.3328 - val_accuracy: 0.8642\n",
      "Epoch 57/100\n",
      "402/402 [==============================] - 2s 5ms/step - loss: 0.4148 - accuracy: 0.8258 - val_loss: 0.3344 - val_accuracy: 0.8643\n",
      "Epoch 58/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4145 - accuracy: 0.8257 - val_loss: 0.3332 - val_accuracy: 0.8643\n",
      "Epoch 59/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4135 - accuracy: 0.8264 - val_loss: 0.3332 - val_accuracy: 0.8644\n",
      "Epoch 60/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4131 - accuracy: 0.8272 - val_loss: 0.3345 - val_accuracy: 0.8615\n",
      "Epoch 61/100\n",
      "402/402 [==============================] - 2s 6ms/step - loss: 0.4139 - accuracy: 0.8267 - val_loss: 0.3339 - val_accuracy: 0.8650\n",
      "Test loss: 0.3294382691383362\n",
      "Test accuracy: 0.867780864238739\n",
      "3572/3572 [==============================] - 3s 838us/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "       Spruce/Fir       0.89      0.83      0.86     41519\n",
      "   Lodgepole Pine       0.87      0.92      0.89     56493\n",
      "   Ponderosa Pine       0.84      0.89      0.86      7151\n",
      "Cottonwood/Willow       0.82      0.70      0.75       549\n",
      "            Aspen       0.76      0.50      0.60      1899\n",
      "      Douglas-fir       0.78      0.64      0.71      3473\n",
      "        Krummholz       0.88      0.82      0.85      3196\n",
      "\n",
      "         accuracy                           0.87    114280\n",
      "        macro avg       0.83      0.76      0.79    114280\n",
      "     weighted avg       0.87      0.87      0.87    114280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06d3ad103a38a5e5980b0a2ddf222334b9b3630c94a7e75a8e45e8afe280f469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
